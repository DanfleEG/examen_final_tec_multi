cols = c(bajo_peso, normal, sobrepeso),
names_to = "estado_nutricional",
values_to = "probabilidad")
# 4. Gráfico de puntos con barras de error (simuladas)
# Para multinom, calcular intervalos aproximados
set.seed(123)  # Para reproducibilidad
n_sim <- 1000  # Número de simulaciones
sim_probs <- list()
for(i in 1:nrow(pred_educ)) {
# Simular coeficientes basados en distribución normal
coef_sim <- MASS::mvrnorm(n_sim,
coef(modelo_corregido),
vcov(modelo_corregido))
# Para cada categoría calcular probabilidades simuladas
probs_sim <- matrix(0, n_sim, 3)
colnames(probs_sim) <- c("bajo_peso", "normal", "sobrepeso")
for(j in 1:n_sim) {
# Calcular probabilidades con coeficientes simulados
# (Aquí simplificamos, en realidad sería más complejo para multinom)
probs_sim[j,] <- predict(modelo_corregido,
newdata = pred_educ[i,],
type = "probs")
}
# Calcular cuantiles
sim_probs[[i]] <- apply(probs_sim, 2,
function(x) quantile(x, c(0.025, 0.975)))
}
# --- VERSIÓN SIMPLE (calculando diferencias) ---
cat("\n=== PROBABILIDADES PREDICHAS POR EDUCACIÓN MATERNA ===\n")
# Calcular probabilidades para cada nivel educativo
niveles <- levels(datos$educacion_madre)
for(nivel in niveles) {
pred_temp <- pred_educ[pred_educ$educacion_madre == nivel, ]
cat(sprintf("\nEducación materna: %s\n", nivel))
cat(sprintf("  Bajo peso: %.1f%%\n", pred_temp$bajo_peso * 100))
cat(sprintf("  Normal: %.1f%%\n", pred_temp$normal * 100))
cat(sprintf("  Sobrepeso: %.1f%%\n", pred_temp$sobrepeso * 100))
}
# Calcular diferencias
cat("\n=== DIFERENCIAS RELATIVAS ===\n")
cat("Comparando con educación primaria (referencia):\n")
primaria <- pred_educ[pred_educ$educacion_madre == "primaria", ]
secundaria <- pred_educ[pred_educ$educacion_madre == "secundaria", ]
superior <- pred_educ[pred_educ$educacion_madre == "superior", ]
cat("\nSecundaria vs Primaria:\n")
cat(sprintf("  Bajo peso: %.1f%% (diferencia: %+.1f%%)\n",
secundaria$bajo_peso * 100,
(secundaria$bajo_peso - primaria$bajo_peso) * 100))
cat(sprintf("  Normal: %.1f%% (diferencia: %+.1f%%)\n",
secundaria$normal * 100,
(secundaria$normal - primaria$normal) * 100))
cat(sprintf("  Sobrepeso: %.1f%% (diferencia: %+.1f%%)\n",
secundaria$sobrepeso * 100,
(secundaria$sobrepeso - primaria$sobrepeso) * 100))
cat("\nSuperior vs Primaria:\n")
cat(sprintf("  Bajo peso: %.1f%% (diferencia: %+.1f%%)\n",
superior$bajo_peso * 100,
(superior$bajo_peso - primaria$bajo_peso) * 100))
cat(sprintf("  Normal: %.1f%% (diferencia: %+.1f%%)\n",
superior$normal * 100,
(superior$normal - primaria$normal) * 100))
cat(sprintf("  Sobrepeso: %.1f%% (diferencia: %+.1f%%)\n",
superior$sobrepeso * 100,
(superior$sobrepeso - primaria$sobrepeso) * 100))
#    Vamos a usar los valores promedios para las variables continuas y la moda para las categóricas (excepto educación_madre)
pred_educ <- expand.grid(
educacion_madre = levels(datos$educacion_madre),  # Los tres niveles
# Valores promedios o modas para el resto
edad_meses = mean(datos$edad_meses),
sexo = factor("masculino", levels = levels(datos$sexo)),
peso_nacimiento = mean(datos$peso_nacimiento),
edad_madre = mean(datos$edad_madre),
imc_madre = mean(datos$imc_madre),
ingreso_familiar = mean(datos$ingreso_familiar),
zona = factor("urbana", levels = levels(datos$zona)),
lactancia_materna = mean(datos$lactancia_materna),
dietas_solidos = factor("no", levels = levels(datos$dietas_solidos))
)
# --- VERSIÓN SIMPLE (calculando diferencias) ---
cat("\n=== PROBABILIDADES PREDICHAS POR EDUCACIÓN MATERNA ===\n")
# Calcular probabilidades para cada nivel educativo
niveles <- levels(datos$educacion_madre)
for(nivel in niveles) {
pred_temp <- pred_educ[pred_educ$educacion_madre == nivel, ]
cat(sprintf("\nEducación materna: %s\n", nivel))
cat(sprintf("  Bajo peso: %.1f%%\n", pred_temp$bajo_peso * 100))
cat(sprintf("  Normal: %.1f%%\n", pred_temp$normal * 100))
cat(sprintf("  Sobrepeso: %.1f%%\n", pred_temp$sobrepeso * 100))
}
# Calcular diferencias
cat("\n=== DIFERENCIAS RELATIVAS ===\n")
cat("Comparando con educación primaria (referencia):\n")
primaria <- pred_educ[pred_educ$educacion_madre == "primaria", ]
secundaria <- pred_educ[pred_educ$educacion_madre == "secundaria", ]
superior <- pred_educ[pred_educ$educacion_madre == "superior", ]
cat("\nSecundaria vs Primaria:\n")
cat(sprintf("  Bajo peso: %.1f%% (diferencia: %+.1f%%)\n",
secundaria$bajo_peso * 100,
(secundaria$bajo_peso - primaria$bajo_peso) * 100))
cat(sprintf("  Normal: %.1f%% (diferencia: %+.1f%%)\n",
secundaria$normal * 100,
(secundaria$normal - primaria$normal) * 100))
cat(sprintf("  Sobrepeso: %.1f%% (diferencia: %+.1f%%)\n",
secundaria$sobrepeso * 100,
(secundaria$sobrepeso - primaria$sobrepeso) * 100))
cat("\nSuperior vs Primaria:\n")
cat(sprintf("  Bajo peso: %.1f%% (diferencia: %+.1f%%)\n",
superior$bajo_peso * 100,
(superior$bajo_peso - primaria$bajo_peso) * 100))
cat(sprintf("  Normal: %.1f%% (diferencia: %+.1f%%)\n",
superior$normal * 100,
(superior$normal - primaria$normal) * 100))
cat(sprintf("  Sobrepeso: %.1f%% (diferencia: %+.1f%%)\n",
superior$sobrepeso * 100,
(superior$sobrepeso - primaria$sobrepeso) * 100))
#    Vamos a usar los valores promedios para las variables continuas y la moda para las categóricas (excepto educación_madre)
pred_educ <- expand.grid(
educacion_madre = levels(datos$educacion_madre),  # Los tres niveles
# Valores promedios o modas para el resto
edad_meses = mean(datos$edad_meses),
sexo = factor("masculino", levels = levels(datos$sexo)),
peso_nacimiento = mean(datos$peso_nacimiento),
edad_madre = mean(datos$edad_madre),
imc_madre = mean(datos$imc_madre),
ingreso_familiar = mean(datos$ingreso_familiar),
zona = factor("urbana", levels = levels(datos$zona)),
lactancia_materna = mean(datos$lactancia_materna),
dietas_solidos = factor("no", levels = levels(datos$dietas_solidos))
)
# 2. Predecir probabilidades
probs_educ <- predict(modelo_sin_id, newdata = pred_educ, type = "probs")
#    Vamos a usar los valores promedios para las variables continuas y la moda para las categóricas (excepto educación_madre)
pred_educ <- expand.grid(
educacion_madre = levels(datos$educacion_madre),  # Los tres niveles
# Valores promedios o modas para el resto
edad_meses = mean(datos$edad_meses),
sexo = factor("masculino", levels = levels(datos$sexo)),
peso_nacimiento = mean(datos$peso_nacimiento),
edad_madre = mean(datos$edad_madre),
imc_madre = mean(datos$imc_madre),
ingreso_familiar = mean(datos$ingreso_familiar),
zona = factor("urbana", levels = levels(datos$zona)),
lactancia_materna = mean(datos$lactancia_materna),
dietas_solidos = factor("no", levels = levels(datos$dietas_solidos))
)
# 2. Predecir probabilidades
probs_educ <- predict(modelo_corregido, newdata = pred_educ, type = "probs")
pred_educ <- cbind(pred_educ, probs_educ)
# 3. Convertir a formato largo
library(tidyr)
pred_educ_largo <- pivot_longer(pred_educ,
cols = c(bajo_peso, normal, sobrepeso),
names_to = "estado_nutricional",
values_to = "probabilidad")
# --- VERSIÓN SIMPLE (calculando diferencias) ---
cat("\n=== PROBABILIDADES PREDICHAS POR EDUCACIÓN MATERNA ===\n")
# Calcular probabilidades para cada nivel educativo
niveles <- levels(datos$educacion_madre)
for(nivel in niveles) {
pred_temp <- pred_educ[pred_educ$educacion_madre == nivel, ]
cat(sprintf("\nEducación materna: %s\n", nivel))
cat(sprintf("  Bajo peso: %.1f%%\n", pred_temp$bajo_peso * 100))
cat(sprintf("  Normal: %.1f%%\n", pred_temp$normal * 100))
cat(sprintf("  Sobrepeso: %.1f%%\n", pred_temp$sobrepeso * 100))
}
# Calcular diferencias
cat("\n=== DIFERENCIAS RELATIVAS ===\n")
cat("Comparando con educación primaria (referencia):\n")
primaria <- pred_educ[pred_educ$educacion_madre == "primaria", ]
secundaria <- pred_educ[pred_educ$educacion_madre == "secundaria", ]
superior <- pred_educ[pred_educ$educacion_madre == "superior", ]
cat("\nSecundaria vs Primaria:\n")
cat(sprintf("  Bajo peso: %.1f%% (diferencia: %+.1f%%)\n",
secundaria$bajo_peso * 100,
(secundaria$bajo_peso - primaria$bajo_peso) * 100))
cat(sprintf("  Normal: %.1f%% (diferencia: %+.1f%%)\n",
secundaria$normal * 100,
(secundaria$normal - primaria$normal) * 100))
cat(sprintf("  Sobrepeso: %.1f%% (diferencia: %+.1f%%)\n",
secundaria$sobrepeso * 100,
(secundaria$sobrepeso - primaria$sobrepeso) * 100))
cat("\nSuperior vs Primaria:\n")
cat(sprintf("  Bajo peso: %.1f%% (diferencia: %+.1f%%)\n",
superior$bajo_peso * 100,
(superior$bajo_peso - primaria$bajo_peso) * 100))
cat(sprintf("  Normal: %.1f%% (diferencia: %+.1f%%)\n",
superior$normal * 100,
(superior$normal - primaria$normal) * 100))
cat(sprintf("  Sobrepeso: %.1f%% (diferencia: %+.1f%%)\n",
superior$sobrepeso * 100,
(superior$sobrepeso - primaria$sobrepeso) * 100))
# --- SECCIÓN 7.1: BONDAD DE AJUSTE GLOBAL ---
# 1. Calcular Pseudo R² de McFadden
# Fórmula: 1 - (log-verosimilitud del modelo / log-verosimilitud del modelo nulo)
logLik_modelo <- as.numeric(logLik(modelo_sin_id))
# --- SECCIÓN 7.1: BONDAD DE AJUSTE GLOBAL ---
# 1. Calcular Pseudo R² de McFadden
# Fórmula: 1 - (log-verosimilitud del modelo / log-verosimilitud del modelo nulo)
logLik_modelo <- as.numeric(logLik(modelo_corregido))
logLik_nulo <- as.numeric(logLik(multinom(estado_nutricional ~ 1, data = datos)))
pseudo_r2_mcfadden <- 1 - (logLik_modelo / logLik_nulo)
# 2. Calcular Pseudo R² de Cox-Snell
# Fórmula: 1 - exp((2/n) * (logLik_nulo - logLik_modelo))
n <- nrow(datos)
pseudo_r2_coxsnell <- 1 - exp((2/n) * (logLik_nulo - logLik_modelo))
# 3. Calcular Pseudo R² de Nagelkerke (ajuste de Cox-Snell)
# Fórmula: Cox-Snell / (1 - exp((2/n) * logLik_nulo))
max_r2 <- 1 - exp((2/n) * logLik_nulo)
pseudo_r2_nagelkerke <- pseudo_r2_coxsnell / max_r2
# 4. Mostrar resultados
cat("\n=== 7.1. BONDAD DE AJUSTE GLOBAL ===\n")
cat("=====================================\n\n")
cat("Medidas de ajuste del modelo:\n")
cat("----------------------------------------\n")
cat(sprintf("Pseudo R² de McFadden:   %.4f\n", pseudo_r2_mcfadden))
cat(sprintf("Pseudo R² de Cox-Snell:   %.4f\n", pseudo_r2_coxsnell))
cat(sprintf("Pseudo R² de Nagelkerke:  %.4f\n", pseudo_r2_nagelkerke))
cat(sprintf("Devianza del modelo:      %.2f\n", deviance(modelo_sin_id)))
# --- SECCIÓN 7.1: BONDAD DE AJUSTE GLOBAL ---
# 1. Calcular Pseudo R² de McFadden
# Fórmula: 1 - (log-verosimilitud del modelo / log-verosimilitud del modelo nulo)
logLik_modelo <- as.numeric(logLik(modelo_corregido))
logLik_nulo <- as.numeric(logLik(multinom(estado_nutricional ~ 1, data = datos)))
pseudo_r2_mcfadden <- 1 - (logLik_modelo / logLik_nulo)
# 2. Calcular Pseudo R² de Cox-Snell
# Fórmula: 1 - exp((2/n) * (logLik_nulo - logLik_modelo))
n <- nrow(datos)
pseudo_r2_coxsnell <- 1 - exp((2/n) * (logLik_nulo - logLik_modelo))
# 3. Calcular Pseudo R² de Nagelkerke (ajuste de Cox-Snell)
# Fórmula: Cox-Snell / (1 - exp((2/n) * logLik_nulo))
max_r2 <- 1 - exp((2/n) * logLik_nulo)
pseudo_r2_nagelkerke <- pseudo_r2_coxsnell / max_r2
# 4. Mostrar resultados
cat("\n=== 7.1. BONDAD DE AJUSTE GLOBAL ===\n")
cat("=====================================\n\n")
cat("Medidas de ajuste del modelo:\n")
cat("----------------------------------------\n")
cat(sprintf("Pseudo R² de McFadden:   %.4f\n", pseudo_r2_mcfadden))
cat(sprintf("Pseudo R² de Cox-Snell:   %.4f\n", pseudo_r2_coxsnell))
cat(sprintf("Pseudo R² de Nagelkerke:  %.4f\n", pseudo_r2_nagelkerke))
cat(sprintf("Devianza del modelo:      %.2f\n", deviance(modelo_corregido)))
cat(sprintf("AIC:                      %.2f\n", AIC(modelo_sin_id)))
# --- SECCIÓN 7.1: BONDAD DE AJUSTE GLOBAL ---
# 1. Calcular Pseudo R² de McFadden
# Fórmula: 1 - (log-verosimilitud del modelo / log-verosimilitud del modelo nulo)
logLik_modelo <- as.numeric(logLik(modelo_corregido))
logLik_nulo <- as.numeric(logLik(multinom(estado_nutricional ~ 1, data = datos)))
pseudo_r2_mcfadden <- 1 - (logLik_modelo / logLik_nulo)
# 2. Calcular Pseudo R² de Cox-Snell
# Fórmula: 1 - exp((2/n) * (logLik_nulo - logLik_modelo))
n <- nrow(datos)
pseudo_r2_coxsnell <- 1 - exp((2/n) * (logLik_nulo - logLik_modelo))
# 3. Calcular Pseudo R² de Nagelkerke (ajuste de Cox-Snell)
# Fórmula: Cox-Snell / (1 - exp((2/n) * logLik_nulo))
max_r2 <- 1 - exp((2/n) * logLik_nulo)
pseudo_r2_nagelkerke <- pseudo_r2_coxsnell / max_r2
# 4. Mostrar resultados
cat("\n=== 7.1. BONDAD DE AJUSTE GLOBAL ===\n")
cat("=====================================\n\n")
cat("Medidas de ajuste del modelo:\n")
cat("----------------------------------------\n")
cat(sprintf("Pseudo R² de McFadden:   %.4f\n", pseudo_r2_mcfadden))
cat(sprintf("Pseudo R² de Cox-Snell:   %.4f\n", pseudo_r2_coxsnell))
cat(sprintf("Pseudo R² de Nagelkerke:  %.4f\n", pseudo_r2_nagelkerke))
cat(sprintf("Devianza del modelo:      %.2f\n", deviance(modelo_corregido)))
cat(sprintf("AIC:                      %.2f\n", AIC(modelo_corregido)))
cat(sprintf("Número de observaciones:  %d\n", n))
# 5. Interpretación de Pseudo R² de McFadden
cat("\nInterpretación del Pseudo R² de McFadden:\n")
cat("----------------------------------------\n")
if (pseudo_r2_mcfadden < 0.2) {
cat("El valor obtenido (", round(pseudo_r2_mcfadden, 3), ") sugiere un ajuste modesto, lo cual es común en modelos de ciencias sociales y de salud.\n", sep = "")
} else if (pseudo_r2_mcfadden < 0.4) {
cat("El valor obtenido (", round(pseudo_r2_mcfadden, 3), ") indica un ajuste moderadamente bueno.\n", sep = "")
} else {
cat("El valor obtenido (", round(pseudo_r2_mcfadden, 3), ") refleja un ajuste muy bueno.\n", sep = "")
}
# 6. Prueba de razón de verosimilitud (ya la tenemos, pero la mostramos)
cat("\nPrueba de razón de verosimilitud (Modelo vs. Nulo):\n")
cat("---------------------------------------------------\n")
cat("Estadístico LR: ", round(2*(logLik_modelo - logLik_nulo), 3), "\n")
cat("Grados de libertad: ", length(coef(modelo_sin_id)), "\n")
# --- SECCIÓN 7.1: BONDAD DE AJUSTE GLOBAL ---
# 1. Calcular Pseudo R² de McFadden
# Fórmula: 1 - (log-verosimilitud del modelo / log-verosimilitud del modelo nulo)
logLik_modelo <- as.numeric(logLik(modelo_corregido))
logLik_nulo <- as.numeric(logLik(multinom(estado_nutricional ~ 1, data = datos)))
pseudo_r2_mcfadden <- 1 - (logLik_modelo / logLik_nulo)
# 2. Calcular Pseudo R² de Cox-Snell
# Fórmula: 1 - exp((2/n) * (logLik_nulo - logLik_modelo))
n <- nrow(datos)
pseudo_r2_coxsnell <- 1 - exp((2/n) * (logLik_nulo - logLik_modelo))
# 3. Calcular Pseudo R² de Nagelkerke (ajuste de Cox-Snell)
# Fórmula: Cox-Snell / (1 - exp((2/n) * logLik_nulo))
max_r2 <- 1 - exp((2/n) * logLik_nulo)
pseudo_r2_nagelkerke <- pseudo_r2_coxsnell / max_r2
# 4. Mostrar resultados
cat("\n=== 7.1. BONDAD DE AJUSTE GLOBAL ===\n")
cat("=====================================\n\n")
cat("Medidas de ajuste del modelo:\n")
cat("----------------------------------------\n")
cat(sprintf("Pseudo R² de McFadden:   %.4f\n", pseudo_r2_mcfadden))
cat(sprintf("Pseudo R² de Cox-Snell:   %.4f\n", pseudo_r2_coxsnell))
cat(sprintf("Pseudo R² de Nagelkerke:  %.4f\n", pseudo_r2_nagelkerke))
cat(sprintf("Devianza del modelo:      %.2f\n", deviance(modelo_corregido)))
cat(sprintf("AIC:                      %.2f\n", AIC(modelo_corregido)))
cat(sprintf("Número de observaciones:  %d\n", n))
# 5. Interpretación de Pseudo R² de McFadden
cat("\nInterpretación del Pseudo R² de McFadden:\n")
cat("----------------------------------------\n")
if (pseudo_r2_mcfadden < 0.2) {
cat("El valor obtenido (", round(pseudo_r2_mcfadden, 3), ") sugiere un ajuste modesto, lo cual es común en modelos de ciencias sociales y de salud.\n", sep = "")
} else if (pseudo_r2_mcfadden < 0.4) {
cat("El valor obtenido (", round(pseudo_r2_mcfadden, 3), ") indica un ajuste moderadamente bueno.\n", sep = "")
} else {
cat("El valor obtenido (", round(pseudo_r2_mcfadden, 3), ") refleja un ajuste muy bueno.\n", sep = "")
}
# 6. Prueba de razón de verosimilitud (ya la tenemos, pero la mostramos)
cat("\nPrueba de razón de verosimilitud (Modelo vs. Nulo):\n")
cat("---------------------------------------------------\n")
cat("Estadístico LR: ", round(2*(logLik_modelo - logLik_nulo), 3), "\n")
cat("Grados de libertad: ", length(coef(modelo_sin_id)), "\n")
# --- SECCIÓN 7.1: BONDAD DE AJUSTE GLOBAL ---
# 1. Calcular Pseudo R² de McFadden
# Fórmula: 1 - (log-verosimilitud del modelo / log-verosimilitud del modelo nulo)
logLik_modelo <- as.numeric(logLik(modelo_corregido))
logLik_nulo <- as.numeric(logLik(multinom(estado_nutricional ~ 1, data = datos)))
pseudo_r2_mcfadden <- 1 - (logLik_modelo / logLik_nulo)
# 2. Calcular Pseudo R² de Cox-Snell
# Fórmula: 1 - exp((2/n) * (logLik_nulo - logLik_modelo))
n <- nrow(datos)
pseudo_r2_coxsnell <- 1 - exp((2/n) * (logLik_nulo - logLik_modelo))
# 3. Calcular Pseudo R² de Nagelkerke (ajuste de Cox-Snell)
# Fórmula: Cox-Snell / (1 - exp((2/n) * logLik_nulo))
max_r2 <- 1 - exp((2/n) * logLik_nulo)
pseudo_r2_nagelkerke <- pseudo_r2_coxsnell / max_r2
# 4. Mostrar resultados
cat("\n=== 7.1. BONDAD DE AJUSTE GLOBAL ===\n")
cat("=====================================\n\n")
cat("Medidas de ajuste del modelo:\n")
cat("----------------------------------------\n")
cat(sprintf("Pseudo R² de McFadden:   %.4f\n", pseudo_r2_mcfadden))
cat(sprintf("Pseudo R² de Cox-Snell:   %.4f\n", pseudo_r2_coxsnell))
cat(sprintf("Pseudo R² de Nagelkerke:  %.4f\n", pseudo_r2_nagelkerke))
cat(sprintf("Devianza del modelo:      %.2f\n", deviance(modelo_corregido)))
cat(sprintf("AIC:                      %.2f\n", AIC(modelo_corregido)))
cat(sprintf("Número de observaciones:  %d\n", n))
# 5. Interpretación de Pseudo R² de McFadden
cat("\nInterpretación del Pseudo R² de McFadden:\n")
cat("----------------------------------------\n")
if (pseudo_r2_mcfadden < 0.2) {
cat("El valor obtenido (", round(pseudo_r2_mcfadden, 3), ") sugiere un ajuste modesto, lo cual es común en modelos de ciencias sociales y de salud.\n", sep = "")
} else if (pseudo_r2_mcfadden < 0.4) {
cat("El valor obtenido (", round(pseudo_r2_mcfadden, 3), ") indica un ajuste moderadamente bueno.\n", sep = "")
} else {
cat("El valor obtenido (", round(pseudo_r2_mcfadden, 3), ") refleja un ajuste muy bueno.\n", sep = "")
}
# 6. Prueba de razón de verosimilitud (ya la tenemos, pero la mostramos)
cat("\nPrueba de razón de verosimilitud (Modelo vs. Nulo):\n")
cat("---------------------------------------------------\n")
cat("Estadístico LR: ", round(2*(logLik_modelo - logLik_nulo), 3), "\n")
cat("Grados de libertad: ", length(coef(modelo_corregido)), "\n")
cat("Valor-p: ", pchisq(2*(logLik_modelo - logLik_nulo), df = length(coef(modelo_corregido)), lower.tail = FALSE), "\n")
# --- SECCIÓN 7.1: BONDAD DE AJUSTE GLOBAL ---
# 1. Calcular Pseudo R² de McFadden
# Fórmula: 1 - (log-verosimilitud del modelo / log-verosimilitud del modelo nulo)
logLik_modelo <- as.numeric(logLik(modelo_corregido))
logLik_nulo <- as.numeric(logLik(multinom(estado_nutricional ~ 1, data = datos)))
pseudo_r2_mcfadden <- 1 - (logLik_modelo / logLik_nulo)
# 2. Calcular Pseudo R² de Cox-Snell
# Fórmula: 1 - exp((2/n) * (logLik_nulo - logLik_modelo))
n <- nrow(datos)
pseudo_r2_coxsnell <- 1 - exp((2/n) * (logLik_nulo - logLik_modelo))
# 3. Calcular Pseudo R² de Nagelkerke (ajuste de Cox-Snell)
# Fórmula: Cox-Snell / (1 - exp((2/n) * logLik_nulo))
max_r2 <- 1 - exp((2/n) * logLik_nulo)
pseudo_r2_nagelkerke <- pseudo_r2_coxsnell / max_r2
# 4. Mostrar resultados
cat("\n=== 7.1. BONDAD DE AJUSTE GLOBAL ===\n")
cat("=====================================\n\n")
cat("Medidas de ajuste del modelo:\n")
cat("----------------------------------------\n")
cat(sprintf("Pseudo R² de McFadden:   %.4f\n", pseudo_r2_mcfadden))
cat(sprintf("Pseudo R² de Cox-Snell:   %.4f\n", pseudo_r2_coxsnell))
cat(sprintf("Pseudo R² de Nagelkerke:  %.4f\n", pseudo_r2_nagelkerke))
cat(sprintf("Devianza del modelo:      %.2f\n", deviance(modelo_corregido)))
cat(sprintf("AIC:                      %.2f\n", AIC(modelo_corregido)))
cat(sprintf("Número de observaciones:  %d\n", n))
# 6. Prueba de razón de verosimilitud (ya la tenemos, pero la mostramos)
cat("\nPrueba de razón de verosimilitud (Modelo vs. Nulo):\n")
cat("---------------------------------------------------\n")
cat("Estadístico LR: ", round(2*(logLik_modelo - logLik_nulo), 3), "\n")
cat("Grados de libertad: ", length(coef(modelo_corregido)), "\n")
cat("Valor-p: ", pchisq(2*(logLik_modelo - logLik_nulo), df = length(coef(modelo_corregido)), lower.tail = FALSE), "\n")
# --- SECCIÓN 7.2: EVALUACIÓN PREDICTIVA ---
library(caret)
# 1. Predecir categorías con el modelo
predicciones <- predict(modelo_corregido, newdata = datos, type = "class")
# 2. Crear matriz de confusión
matriz_confusion <- confusionMatrix(data = predicciones,
reference = datos$estado_nutricional)
# 3. Mostrar resultados
cat("\n=== 7.2. MATRIZ DE CONFUSIÓN Y CAPACIDAD PREDICTIVA ===\n")
cat("========================================================\n\n")
# Matriz de confusión
cat("MATRIZ DE CONFUSIÓN:\n")
print(matriz_confusion$table)
# Métricas generales
cat("\nMÉTRICAS DE PRECISIÓN:\n")
cat("-----------------------\n")
cat(sprintf("Exactitud global (Accuracy): %.2f%%\n",
matriz_confusion$overall["Accuracy"] * 100))
cat(sprintf("Intervalo de confianza 95%%: %.2f%% - %.2f%%\n",
matriz_confusion$overall["AccuracyLower"] * 100,
matriz_confusion$overall["AccuracyUpper"] * 100))
cat(sprintf("Valor-p (Exactitud > No Information Rate): %.4f\n",
matriz_confusion$overall["AccuracyPValue"]))
cat(sprintf("Tasa de error: %.2f%%\n", (1 - matriz_confusion$overall["Accuracy"]) * 100))
# Métricas por clase
cat("\nMÉTRICAS POR CLASE:\n")
cat("-------------------\n")
for(clase in levels(datos$estado_nutricional)) {
cat(sprintf("\nCategoría: %s\n", clase))
cat(sprintf("  Sensibilidad: %.2f%%\n",
matriz_confusion$byClass[paste0("Class: ", clase), "Sensitivity"] * 100))
cat(sprintf("  Especificidad: %.2f%%\n",
matriz_confusion$byClass[paste0("Class: ", clase), "Specificity"] * 100))
cat(sprintf("  Valor predictivo positivo: %.2f%%\n",
matriz_confusion$byClass[paste0("Class: ", clase), "Pos Pred Value"] * 100))
cat(sprintf("  Valor predictivo negativo: %.2f%%\n",
matriz_confusion$byClass[paste0("Class: ", clase), "Neg Pred Value"] * 100))
}
# Estadístico Kappa
cat("\nACUERDO MÁS ALLÁ DEL AZAR:\n")
cat("---------------------------\n")
cat(sprintf("Estadístico Kappa de Cohen: %.3f\n",
matriz_confusion$overall["Kappa"]))
cat(sprintf("Interpretación: %s\n",
case_when(
matriz_confusion$overall["Kappa"] < 0.2 ~ "Acuerdo insignificante",
matriz_confusion$overall["Kappa"] < 0.4 ~ "Acuerdo bajo",
matriz_confusion$overall["Kappa"] < 0.6 ~ "Acuerdo moderado",
matriz_confusion$overall["Kappa"] < 0.8 ~ "Acuerdo sustancial",
TRUE ~ "Acuerdo casi perfecto"
)))
# Comparación con tasa base (No Information Rate)
cat("\nCOMPARACIÓN CON TASA BASE (NO INFORMATION RATE):\n")
cat("-------------------------------------------------\n")
cat(sprintf("Tasa base (categoría más frecuente): %.2f%%\n",
matriz_confusion$overall["AccuracyNull"] * 100))
cat(sprintf("Mejora relativa del modelo: %.1f%%\n",
((matriz_confusion$overall["Accuracy"] - matriz_confusion$overall["AccuracyNull"]) /
(1 - matriz_confusion$overall["AccuracyNull"]) * 100)))
# --- SECCIÓN 7.2: EVALUACIÓN PREDICTIVA ---
library(caret)
# 1. Predecir categorías con el modelo
predicciones <- predict(modelo_corregido, newdata = datos, type = "class")
# 2. Crear matriz de confusión
matriz_confusion <- confusionMatrix(data = predicciones,
reference = datos$estado_nutricional)
# 3. Mostrar resultados
cat("\n=== 7.2. MATRIZ DE CONFUSIÓN Y CAPACIDAD PREDICTIVA ===\n")
cat("========================================================\n\n")
# Matriz de confusión
cat("MATRIZ DE CONFUSIÓN:\n")
print(matriz_confusion$table)
# Métricas generales
cat("\nMÉTRICAS DE PRECISIÓN:\n")
cat("-----------------------\n")
cat(sprintf("Exactitud global (Accuracy): %.2f%%\n",
matriz_confusion$overall["Accuracy"] * 100))
cat(sprintf("Intervalo de confianza 95%%: %.2f%% - %.2f%%\n",
matriz_confusion$overall["AccuracyLower"] * 100,
matriz_confusion$overall["AccuracyUpper"] * 100))
cat(sprintf("Valor-p (Exactitud > No Information Rate): %.4f\n",
matriz_confusion$overall["AccuracyPValue"]))
cat(sprintf("Tasa de error: %.2f%%\n", (1 - matriz_confusion$overall["Accuracy"]) * 100))
# Métricas por clase
cat("\nMÉTRICAS POR CLASE:\n")
cat("-------------------\n")
for(clase in levels(datos$estado_nutricional)) {
cat(sprintf("\nCategoría: %s\n", clase))
cat(sprintf("  Sensibilidad: %.2f%%\n",
matriz_confusion$byClass[paste0("Class: ", clase), "Sensitivity"] * 100))
cat(sprintf("  Especificidad: %.2f%%\n",
matriz_confusion$byClass[paste0("Class: ", clase), "Specificity"] * 100))
cat(sprintf("  Valor predictivo positivo: %.2f%%\n",
matriz_confusion$byClass[paste0("Class: ", clase), "Pos Pred Value"] * 100))
cat(sprintf("  Valor predictivo negativo: %.2f%%\n",
matriz_confusion$byClass[paste0("Class: ", clase), "Neg Pred Value"] * 100))
}
# Estadístico Kappa
cat("\nACUERDO MÁS ALLÁ DEL AZAR:\n")
cat("---------------------------\n")
cat(sprintf("Estadístico Kappa de Cohen: %.3f\n",
matriz_confusion$overall["Kappa"]))
cat(sprintf("Interpretación: %s\n",
case_when(
matriz_confusion$overall["Kappa"] < 0.2 ~ "Acuerdo insignificante",
matriz_confusion$overall["Kappa"] < 0.4 ~ "Acuerdo bajo",
matriz_confusion$overall["Kappa"] < 0.6 ~ "Acuerdo moderado",
matriz_confusion$overall["Kappa"] < 0.8 ~ "Acuerdo sustancial",
TRUE ~ "Acuerdo casi perfecto"
)))
# Comparación con tasa base (No Information Rate)
cat("\nCOMPARACIÓN CON TASA BASE (NO INFORMATION RATE):\n")
cat("-------------------------------------------------\n")
cat(sprintf("Tasa base (categoría más frecuente): %.2f%%\n",
matriz_confusion$overall["AccuracyNull"] * 100))
cat(sprintf("Mejora relativa del modelo: %.1f%%\n",
((matriz_confusion$overall["Accuracy"] - matriz_confusion$overall["AccuracyNull"]) /
(1 - matriz_confusion$overall["AccuracyNull"]) * 100)))
